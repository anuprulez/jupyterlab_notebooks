{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2faafe31-d556-46af-99de-e72a0b584fdf",
   "metadata": {},
   "source": [
    "## Sharing machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51162e44-3590-46c3-8419-e6c8df513d6c",
   "metadata": {},
   "source": [
    "### Save and retrieve Scikit-learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56f8a4ad-0a7a-476b-8c53-f8bd2742d03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a model.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "clr = RandomForestClassifier()\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "# accuracy on test data with trained model\n",
    "clr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "912d9ce9-49a9-4b71-9968-f838173e34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into ONNX format\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "initial_type = [('float_input', FloatTensorType([None, 4]))]\n",
    "onx = convert_sklearn(clr, initial_types=initial_type)\n",
    "\n",
    "# save trained model\n",
    "with open(\"saved_models/rf_iris.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d334b91-001b-4416-ad6c-eddda8aa0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prediction with ONNX Runtime\n",
    "import onnxruntime as rt\n",
    "import numpy\n",
    "\n",
    "# retrieve trained model\n",
    "sess = rt.InferenceSession(\"saved_models/rf_iris.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "\n",
    "# predict labels of test data\n",
    "pred_onx = sess.run([label_name], {input_name: X_test.astype(numpy.float32)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e15a26d-05fa-4147-a58e-d84ada04f031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 2, 1, 1, 1, 0, 1, 0, 0, 0, 2, 1, 2, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 2, 1, 0, 1, 2, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_onx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be6798ff-dc47-4556-a85a-8de5c1af8a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics as score\n",
    "\n",
    "# accuracy on test data using retrieved model\n",
    "score.accuracy_score(y_test, pred_onx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb57477-c84d-4238-a96a-f973ce174247",
   "metadata": {},
   "source": [
    "### Save and retrieve Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db5488eb-aa5e-473c-a396-f9ce5c0e6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "import tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed35e925-05b9-4d29-a3c2-c74849bca367",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c27b3c28-2c12-4e3a-9a50-2878d80192d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c72bb62-45dc-430e-a9f4-246b03bbc048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5a2a0d44-5d34-48d9-9b7e-1021b54a6355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_7'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0add51fc-ebee-462d-a707-9cce7e01024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d622f0bb-fade-4026-833e-42d3e1fe1445",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "827684b3-2b36-4092-9e16-d3d24ef07892",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49787b09-81a7-4132-a379-17d50645ad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Epoch 1, Loss: 0.13305729627609253, Accuracy: 95.99333190917969, \n",
      "Training epoch: 2\n",
      "Epoch 2, Loss: 0.04282589256763458, Accuracy: 98.66166687011719, \n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  print(\"Training epoch: {}\".format(str(epoch+1)))\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382651b-bdde-4d0c-8c55-d1f6ceb83846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f5d338be-6d58-423d-8c31-6999a802f235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'tf_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "6929cdca-4c31-43b7-bbfd-0a9e1935f13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_TF_MODULE_IGNORED_PROPERTIES', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_activity_regularizer', '_add_trackable', '_add_variable_with_custom_getter', '_assert_compile_was_called', '_assert_weights_created', '_auto_track_sub_layers', '_autocast', '_autographed_call', '_base_model_initialized', '_build_input_shape', '_call_accepts_kwargs', '_call_arg_was_passed', '_call_fn_arg_defaults', '_call_fn_arg_positions', '_call_fn_args', '_call_full_argspec', '_callable_losses', '_cast_single_input', '_check_call_args', '_checkpoint_dependencies', '_clear_losses', '_compile_was_called', '_compiled_trainable_state', '_compute_dtype', '_compute_dtype_object', '_compute_output_and_mask_jointly', '_configure_steps_per_execution', '_dedup_weights', '_default_training_arg', '_deferred_dependencies', '_distribution_strategy', '_dtype', '_dtype_policy', '_dynamic', '_eager_losses', '_expects_mask_arg', '_expects_training_arg', '_flatten', '_flatten_layers', '_functional_construction_call', '_gather_children_attribute', '_gather_saveables_for_checkpoint', '_get_call_arg_value', '_get_callback_model', '_get_compile_args', '_get_distribution_strategy', '_get_existing_metric', '_get_input_masks', '_get_node_attribute_at_index', '_get_optimizer', '_get_save_spec', '_get_trainable_state', '_handle_activity_regularization', '_handle_deferred_dependencies', '_handle_weight_regularization', '_in_multi_worker_mode', '_inbound_nodes', '_inbound_nodes_value', '_infer_output_signature', '_init_batch_counters', '_init_call_fn_args', '_init_set_name', '_initial_weights', '_input_spec', '_instrument_layer_creation', '_instrumented_keras_api', '_instrumented_keras_layer_class', '_instrumented_keras_model_class', '_is_compiled', '_is_graph_network', '_is_layer', '_is_model_for_instrumentation', '_keras_api_names', '_keras_api_names_v1', '_keras_tensor_symbolic_call', '_layers', '_list_extra_dependencies_for_serialization', '_list_functions_for_serialization', '_lookup_dependency', '_losses', '_map_resources', '_maybe_build', '_maybe_cast_inputs', '_maybe_create_attribute', '_maybe_initialize_trackable', '_maybe_load_initial_epoch_from_ckpt', '_metrics', '_metrics_lock', '_must_restore_from_config', '_name', '_name_based_attribute_restore', '_name_based_restores', '_name_scope', '_no_dependency', '_non_trainable_weights', '_obj_reference_counts', '_obj_reference_counts_dict', '_object_identifier', '_outbound_nodes', '_outbound_nodes_value', '_predict_counter', '_preload_simple_restoration', '_preserve_input_structure_in_config', '_reset_compile_cache', '_restore_from_checkpoint_position', '_run_eagerly', '_saved_model_inputs_spec', '_self_name_based_restores', '_self_saveable_object_factories', '_self_setattr_tracking', '_self_unconditional_checkpoint_dependencies', '_self_unconditional_deferred_dependencies', '_self_unconditional_dependency_names', '_self_update_uid', '_set_call_arg_value', '_set_connectivity_metadata', '_set_dtype_policy', '_set_inputs', '_set_mask_keras_history_checked', '_set_mask_metadata', '_set_save_spec', '_set_trainable_state', '_set_training_mode', '_setattr_tracking', '_should_cast_single_input', '_should_compute_mask', '_should_eval', '_single_restoration_from_checkpoint_position', '_split_out_first_arg', '_stateful', '_steps_per_execution', '_supports_masking', '_symbolic_call', '_test_counter', '_tf_api_names', '_tf_api_names_v1', '_thread_local', '_track_trackable', '_trackable_saved_model_saver', '_trackable_saver', '_tracking_metadata', '_train_counter', '_trainable', '_trainable_weights', '_training_state', '_unconditional_checkpoint_dependencies', '_unconditional_dependency_names', '_undeduplicated_weights', '_update_uid', '_updated_config', '_updates', '_validate_compile', 'activity_regularizer', 'add_loss', 'add_metric', 'add_update', 'add_variable', 'add_weight', 'apply', 'build', 'built', 'call', 'compile', 'compiled_loss', 'compiled_metrics', 'compute_dtype', 'compute_mask', 'compute_output_shape', 'compute_output_signature', 'conv1', 'count_params', 'd1', 'd2', 'distribute_strategy', 'dtype', 'dtype_policy', 'dynamic', 'evaluate', 'evaluate_generator', 'fit', 'fit_generator', 'flatten', 'from_config', 'get_config', 'get_input_at', 'get_input_mask_at', 'get_input_shape_at', 'get_layer', 'get_losses_for', 'get_output_at', 'get_output_mask_at', 'get_output_shape_at', 'get_updates_for', 'get_weights', 'history', 'inbound_nodes', 'input', 'input_mask', 'input_names', 'input_shape', 'input_spec', 'inputs', 'layers', 'load_weights', 'losses', 'make_predict_function', 'make_test_function', 'make_train_function', 'metrics', 'metrics_names', 'name', 'name_scope', 'non_trainable_variables', 'non_trainable_weights', 'optimizer', 'outbound_nodes', 'output', 'output_mask', 'output_names', 'output_shape', 'outputs', 'predict', 'predict_function', 'predict_generator', 'predict_on_batch', 'predict_step', 'reset_metrics', 'reset_states', 'run_eagerly', 'save', 'save_weights', 'set_weights', 'state_updates', 'stateful', 'stop_training', 'submodules', 'summary', 'supports_masking', 'test_function', 'test_on_batch', 'test_step', 'to_json', 'to_yaml', 'train_function', 'train_on_batch', 'train_step', 'trainable', 'trainable_variables', 'trainable_weights', 'updates', 'variable_dtype', 'variables', 'weights', 'with_name_scope']\n"
     ]
    }
   ],
   "source": [
    "print(dir(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "21803cd0-983b-47d1-a5b2-23daea943572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-06-15 08:38:16,024 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2021-06-15 08:38:16,154 - INFO - Signatures found in model: [serving_default].\n",
      "2021-06-15 08:38:16,155 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2021-06-15 08:38:16,155 - INFO - Output names: ['output_1']\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tf2onnx/tf_loader.py:603: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-06-15 08:38:16,395 - WARNING - From /opt/conda/lib/python3.9/site-packages/tf2onnx/tf_loader.py:603: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-06-15 08:38:16,551 - INFO - Using tensorflow=2.4.1, onnx=1.9.0, tf2onnx=1.8.5/50049d\n",
      "2021-06-15 08:38:16,551 - INFO - Using opset <onnx, 9>\n",
      "2021-06-15 08:38:16,987 - INFO - Computed 0 values for constant folding\n",
      "2021-06-15 08:38:17,854 - INFO - Optimizing ONNX model\n",
      "2021-06-15 08:38:18,258 - INFO - After optimization: Cast -1 (1->0), Const +1 (7->8), Identity -5 (5->0), Reshape +1 (1->2), Transpose -1 (2->1)\n",
      "2021-06-15 08:38:18,298 - INFO - \n",
      "2021-06-15 08:38:18,298 - INFO - Successfully converted TensorFlow model tf_model to ONNX\n",
      "2021-06-15 08:38:18,298 - INFO - Model inputs: ['input_1:0']\n",
      "2021-06-15 08:38:18,298 - INFO - Model outputs: ['output_1']\n",
      "2021-06-15 08:38:18,299 - INFO - ONNX model is saved at tfmodel.onnx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python -m tf2onnx.convert --saved-model tf_model --output tfmodel.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96cee9c-460f-4606-8926-d21647a2c473",
   "metadata": {},
   "source": [
    "### Retrieve saved tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "23abb6d8-b933-4e74-8830-249dad9ccbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "b75fc9f4-1c49-4b8e-91d5-2598fd271cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = onnx.load(\"tfmodel.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "83473b7d-3b16-4200-b20d-1ff9d8c4b1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ByteSize', 'Clear', 'ClearExtension', 'ClearField', 'CopyFrom', 'DESCRIPTOR', 'DiscardUnknownFields', 'Extensions', 'FindInitializationErrors', 'FromString', 'HasExtension', 'HasField', 'IsInitialized', 'ListFields', 'MergeFrom', 'MergeFromString', 'ParseFromString', 'RegisterExtension', 'SerializePartialToString', 'SerializeToString', 'SetInParent', 'UnknownFields', 'WhichOneof', '_CheckCalledFromGeneratedFile', '_SetListener', '__class__', '__deepcopy__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__unicode__', '_extensions_by_name', '_extensions_by_number', 'doc_string', 'domain', 'graph', 'ir_version', 'metadata_props', 'model_version', 'opset_import', 'producer_name', 'producer_version', 'training_info']\n"
     ]
    }
   ],
   "source": [
    "print(dir(loaded_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "b93221f2-5073-48a4-b2a4-193f9bdf0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_loaded_model = prepare(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "3cc1fc94-5987-4b98-bf87-713d07bf606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_graph', '_inputs', '_onnx_op_list', '_outputs', '_tensor_dict', '_tf_module', 'export_graph', 'graph', 'inputs', 'onnx_op_list', 'outputs', 'run', 'signatures', 'tensor_dict', 'tf_module']\n"
     ]
    }
   ],
   "source": [
    "print(dir(tf_loaded_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "d8cdd391-ea82-4859-b013-8c8670faa55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_1:0': TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1_tf_0_1e47038a')}"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_loaded_model.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "43668239-f15c-4031-9cfd-fa46b74eeb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_loaded_model.export_graph(\"loaded_model\")\n",
    "#saved_loaded_model = tf.saved_model.load(\"loaded_model\")\n",
    "#print(dir(saved_loaded_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "3e4cda9b-e5a5-41dd-bdd9-0456f9f4352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "a69cd042-a72c-4aa5-8601-b9df84e199a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_1:0']"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_loaded_model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "ca4c440c-d8b1-4dc1-a487-e546bdf92eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output_1']"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_loaded_model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "fc86423a-4b68-4b4b-94c4-d9ee46224e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_loaded_model.tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "c56971ea-0522-44fa-92e8-016592ddd9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "\n",
    "#onnx-tf convert -i tfmodel.onnx -o \"loaded_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a47f85-e75d-47e4-b5b7-e6ca8a66a84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  # 'input_1:0': TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1_tf_0_da1f0fb4'\n",
    "  # {\"input_1:0\": images[0], \"dtype\": tf.float32, \"name\": 'input_1_tf_0_da1f0fb4'}\n",
    "  # output = prepare(onnx_model).run(input)\n",
    "  # {'input_1:0': TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1_tf_0_58f50004')}\n",
    "  #img_proto = tf.make_tensor_proto(images[0])\n",
    "  #img_np = tf.make_ndarray(img_proto)\n",
    "  #print(img_np)\n",
    "  true_labels = []\n",
    "  predicted_labels = []\n",
    "  for i, item in enumerate(images):\n",
    "      prediction = tf_loaded_model.run(images[i])\n",
    "      #prediction = int(np.argmax(np.array(predictions).squeeze(), axis=0))\n",
    "      true_labels.append(labels[i])\n",
    "      predicted_labels.append(prediction)\n",
    "  t_loss = loss_object(true_labels, predicted_labels)\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(true_labels, predicted_labels)\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    ts = test_images #.numpy()\n",
    "    test_step(ts, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Test Loss: {test_loss.result()}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37004f-a79f-48ec-a967-84e8b1d0c944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6bf6e4-a31e-41ae-9b4d-4d8ebdbad63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c33853-576c-4119-8c89-c8473412d8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa940b3-48cc-4664-9a42-2d75493c6b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.core.protobuf import saved_model_pb2\n",
    "from tensorflow.python.util import compat\n",
    "from google.protobuf import text_format\n",
    "\n",
    "graph_def = tf.compat.v1.GraphDef()\n",
    "\n",
    "# These are set to the default names from exported models, update as needed.\n",
    "filename = \"loaded_model/saved_model.pb\"\n",
    "\n",
    "#INPUT_TENSOR_NAME = model.conv1.name + \":0\"\n",
    "#OUTPUT_TENSOR_NAME = model.d2.name + \":0\"\n",
    "\n",
    "print(INPUT_TENSOR_NAME, OUTPUT_TENSOR_NAME)\n",
    "\n",
    "# Import the TF graph\n",
    "with gfile.FastGFile(filename, 'rb') as f:\n",
    "    data = compat.as_bytes(f.read())\n",
    "    sm = saved_model_pb2.SavedModel()\n",
    "    sm.ParseFromString(data)\n",
    "    #graph_def = tf.GraphDef()\n",
    "    #content = f.read()\n",
    "    #a = text_format.Merge(content, graph_def)\n",
    "    #graph_def.ParseFromString(content)\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        #g_in = tf.import_graph_def(sm.meta_graphs[0].graph_def)\n",
    "        #tf.import_graph_def(sm.meta_graphs[0].graph_def)\n",
    "        tf.import_graph_def(sm.meta_graphs[0].graph_def, name=\"\")\n",
    "    \n",
    "print(graph)\n",
    "print(dir(graph))\n",
    "#input_tensor = graph.get_tensor_by_name(INPUT_TENSOR_NAME)\n",
    "#output_tensor = graph.get_tensor_by_name(OUTPUT_TENSOR_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "14880618-c980-4559-97d2-58c3a47b042d",
   "metadata": {},
   "outputs": [
    {
     "ename": "DecodeError",
     "evalue": "Error parsing message",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDecodeError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-cd90430bdc12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPB_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDecodeError\u001b[0m: Error parsing message"
     ]
    }
   ],
   "source": [
    "INPUT_TENSOR_NAME = model.conv1.name\n",
    "OUTPUT_TENSOR_NAME = model.d2.name\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "PB_PATH = \"tf_model/saved_model.pb\" #\"loaded_model/saved_model.pb\"\n",
    "\n",
    "with gfile.FastGFile(PB_PATH,'rb') as f:\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "with tf.Graph().as_default() as graph:\n",
    "    tf.import_graph_def(graph_def, name=\"\")\n",
    "\n",
    "input_tensor = graph.get_tensor_by_name(INPUT_TENSOR_NAME)\n",
    "output_tensor = graph.get_tensor_by_name(OUTPUT_TENSOR_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31f25c2-18db-4da4-86b8-bb74d6a8f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "\n",
    "INPUT_TENSOR_NAME = model.conv1.name\n",
    "OUTPUT_TENSOR_NAME = model.d2.name\n",
    "\n",
    "PB_PATH = \"loaded_model/saved_model.pb\"\n",
    "\n",
    "with tf.io.gfile.GFile(PB_PATH,'r') as f:\n",
    "  proto_b = f.read()\n",
    "  graph_def = tf.compat.v1.GraphDef()\n",
    "  text_format.Merge(proto_b, graph_def)\n",
    "  graph_def.ParseFromString(graph_def)\n",
    "\n",
    "with tf.Graph().as_default() as graph:\n",
    "  tf.import_graph_def(graph_def, name=\"\")\n",
    "\n",
    "input_tensor = graph.get_tensor_by_name(INPUT_TENSOR_NAME)\n",
    "output_tensor = graph.get_tensor_by_name(OUTPUT_TENSOR_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
