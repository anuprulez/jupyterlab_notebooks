{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2faafe31-d556-46af-99de-e72a0b584fdf",
   "metadata": {},
   "source": [
    "## Sharing machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51162e44-3590-46c3-8419-e6c8df513d6c",
   "metadata": {},
   "source": [
    "### Save and retrieve Scikit-learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56f8a4ad-0a7a-476b-8c53-f8bd2742d03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a model.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "clr = RandomForestClassifier()\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "# accuracy on test data with trained model\n",
    "clr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "912d9ce9-49a9-4b71-9968-f838173e34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into ONNX format\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "initial_type = [('float_input', FloatTensorType([None, 4]))]\n",
    "onx = convert_sklearn(clr, initial_types=initial_type)\n",
    "\n",
    "# save trained model\n",
    "with open(\"saved_models/rf_iris.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d334b91-001b-4416-ad6c-eddda8aa0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prediction with ONNX Runtime\n",
    "import onnxruntime as rt\n",
    "import numpy\n",
    "\n",
    "# retrieve trained model\n",
    "sess = rt.InferenceSession(\"saved_models/rf_iris.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "\n",
    "# predict labels of test data\n",
    "pred_onx = sess.run([label_name], {input_name: X_test.astype(numpy.float32)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e15a26d-05fa-4147-a58e-d84ada04f031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 2, 1, 1, 1, 0, 1, 0, 0, 0, 2, 1, 2, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 2, 1, 0, 1, 2, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_onx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be6798ff-dc47-4556-a85a-8de5c1af8a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics as score\n",
    "\n",
    "# accuracy on test data using retrieved model\n",
    "score.accuracy_score(y_test, pred_onx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb57477-c84d-4238-a96a-f973ce174247",
   "metadata": {},
   "source": [
    "## Save Tensorflow model as ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "db5488eb-aa5e-473c-a396-f9ce5c0e6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "import tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "ed35e925-05b9-4d29-a3c2-c74849bca367",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.tensorflow.org/tutorials/quickstart/advanced\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "c27b3c28-2c12-4e3a-9a50-2878d80192d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "0c72bb62-45dc-430e-a9f4-246b03bbc048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "0add51fc-ebee-462d-a707-9cce7e01024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "d622f0bb-fade-4026-833e-42d3e1fe1445",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "827684b3-2b36-4092-9e16-d3d24ef07892",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(images, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "49787b09-81a7-4132-a379-17d50645ad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.12848874926567078, Accuracy: 96.01667022705078, Test Loss: 0.059200361371040344, Test Accuracy: 98.05999755859375\n",
      "Epoch 2, Loss: 0.04051610454916954, Accuracy: 98.7066650390625, Test Loss: 0.05137334018945694, Test Accuracy: 98.19999694824219\n",
      "Epoch 3, Loss: 0.02006339281797409, Accuracy: 99.36166381835938, Test Loss: 0.049598418176174164, Test Accuracy: 98.36000061035156\n",
      "Epoch 4, Loss: 0.012742787599563599, Accuracy: 99.58333587646484, Test Loss: 0.05011746659874916, Test Accuracy: 98.56999969482422\n",
      "Epoch 5, Loss: 0.007653344888240099, Accuracy: 99.76499938964844, Test Loss: 0.06342844665050507, Test Accuracy: 98.3499984741211\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Loss: {test_loss.result()}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "f5d338be-6d58-423d-8c31-6999a802f235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'tf_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "17e6b6e1-296c-4082-8cec-517060901c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-06-15 12:52:44,034 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2021-06-15 12:52:44,161 - INFO - Signatures found in model: [serving_default].\n",
      "2021-06-15 12:52:44,161 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2021-06-15 12:52:44,161 - INFO - Output names: ['output_1']\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tf2onnx/tf_loader.py:603: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-06-15 12:52:44,425 - WARNING - From /opt/conda/lib/python3.9/site-packages/tf2onnx/tf_loader.py:603: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-06-15 12:52:44,577 - INFO - Using tensorflow=2.4.1, onnx=1.9.0, tf2onnx=1.8.5/50049d\n",
      "2021-06-15 12:52:44,577 - INFO - Using opset <onnx, 7>\n",
      "2021-06-15 12:52:45,084 - INFO - Computed 0 values for constant folding\n",
      "2021-06-15 12:52:46,187 - INFO - Optimizing ONNX model\n",
      "2021-06-15 12:52:46,479 - INFO - After optimization: Cast -1 (1->0), Const +1 (7->8), Identity -5 (5->0), Reshape +1 (1->2), Transpose -1 (2->1)\n",
      "2021-06-15 12:52:46,527 - INFO - \n",
      "2021-06-15 12:52:46,528 - INFO - Successfully converted TensorFlow model tf_model to ONNX\n",
      "2021-06-15 12:52:46,528 - INFO - Model inputs: ['input_1:0', 'new_shape__12', 'const_fold_opt__13', 'StatefulPartitionedCall/my_model_6/dense_13/MatMul/ReadVariableOp:0', 'StatefulPartitionedCall/my_model_6/dense_13/BiasAdd/ReadVariableOp:0', 'StatefulPartitionedCall/my_model_6/dense_12/MatMul/ReadVariableOp:0', 'StatefulPartitionedCall/my_model_6/dense_12/BiasAdd/ReadVariableOp:0', 'StatefulPartitionedCall/my_model_6/conv2d_6/Conv2D/ReadVariableOp:0', 'StatefulPartitionedCall/my_model_6/conv2d_6/BiasAdd/ReadVariableOp:0']\n",
      "2021-06-15 12:52:46,528 - INFO - Model outputs: ['output_1']\n",
      "2021-06-15 12:52:46,528 - INFO - ONNX model is saved at mnist_model.onnx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python -m tf2onnx.convert --saved-model tf_model --output mnist_model.onnx --opset 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96cee9c-460f-4606-8926-d21647a2c473",
   "metadata": {},
   "source": [
    "## Retrieve ONNX model as Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "23abb6d8-b933-4e74-8830-249dad9ccbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "b75fc9f4-1c49-4b8e-91d5-2598fd271cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = onnx.load(\"mnist_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "b93221f2-5073-48a4-b2a4-193f9bdf0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_loaded_model = prepare(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "43668239-f15c-4031-9cfd-fa46b74eeb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_loaded_model.export_graph(\"loaded_model\")\n",
    "#saved_loaded_model = tf.saved_model.load(\"loaded_model\")\n",
    "#print(dir(saved_loaded_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "12a47f85-e75d-47e4-b5b7-e6ca8a66a84e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test loss: 0.06342846155166626\n",
      "Mean test accuracy: 98.3526382446289\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "total_test_accuracy = []\n",
    "total_test_loss = []\n",
    "\n",
    "def predict_test(images, labels):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "  true_labels = []\n",
    "  predicted_labels = []\n",
    "  for i, item in enumerate(images):\n",
    "      prediction = tf_loaded_model.run(item, training=False)\n",
    "      pred = np.array(prediction).squeeze()\n",
    "      true_labels.append([labels[i].numpy()])\n",
    "      predicted_labels.append(pred)\n",
    "  t_loss = loss_object(true_labels, predicted_labels)  \n",
    "  return test_loss(t_loss), test_accuracy(labels, predicted_labels)\n",
    "\n",
    "\n",
    "for test_images, test_labels in test_ds:\n",
    "  ls, acc = predict_test(test_images, test_labels)\n",
    "  loss = test_loss.result()\n",
    "  accuracy = test_accuracy.result() * 100\n",
    "  total_test_accuracy.append(accuracy.numpy())\n",
    "  total_test_loss.append(loss.numpy())\n",
    "\n",
    "print(\"Mean test loss: {}\".format(np.mean(total_test_loss)))\n",
    "print(\"Mean test accuracy: {}\".format(np.mean(total_test_accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37004f-a79f-48ec-a967-84e8b1d0c944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6bf6e4-a31e-41ae-9b4d-4d8ebdbad63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c33853-576c-4119-8c89-c8473412d8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa940b3-48cc-4664-9a42-2d75493c6b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14880618-c980-4559-97d2-58c3a47b042d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31f25c2-18db-4da4-86b8-bb74d6a8f8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
